#!/bin/bash

set -x

available() {
  command -v $1 > /dev/null
}

select_container_manager() {
  if available podman; then
    echo "podman"
  elif available docker; then
    echo "docker"
  else
    echo "podman"
  fi
}

image_available() {
  local llm_store="$1"
  [ -n "$($conman $llm_store images -q $image_name 2> /dev/null)" ]
}

conman_build_gguf() {
  local conman="$1"
  local uuid="$2"
  local model="$3"
  echo "$containerfile" | $conman build -t $image_name -
  $conman image prune -f --filter label=STAGE=$uuid
  $conman export $image_name | $conman $llm_store import - $image_name
  $conman rmi -f $image_name
}

check_if_in_hf_db() {
  local llm_store="$1"
  local vol="$2"
  local conman_run="$3"
  local host="raw.githubusercontent.com"
  local url="https://$host/ericcurtin/podman-llm/main/hf-db/$image_name"
  if ! image_available "$llm_store" && local db_file="$(curl -fsSL $url)"; then
    local hf_repo="$(echo "$db_file" | sed -ne "s/^hf-repo\s//pg" | xargs)"
    local model="$(echo "$db_file" | sed -ne "s/^model\s//pg" | xargs)"
    local podman_llm_image="quay.io/podman-llm/podman-llm:latest"
    local uuid="$(cat /proc/sys/kernel/random/uuid)"
    local containerfile="$(echo "FROM $podman_llm_image AS builder
LABEL STAGE=$uuid
RUN huggingface-cli download $hf_repo $model
RUN ln -s \$(huggingface-cli download $hf_repo $model) /$model

FROM scratch
COPY --from=builder /$model /
LABEL MODEL=/$model")"
    conman_build_gguf "$conman" "$uuid" "$model"
  fi
}

get_model() {
  local image_name="$1"
  podman $llm_store inspect -f '{{ index .Config.Labels "MODEL"}}' $image_name
}

attempt_hf_pull() {
  local llm_store="$1"
  local image_name="$2"
  local conman_run="$3"
  check_if_in_hf_db "$llm_store" "$vol" "$conman_run"
}

main() {
  set -eu -o pipefail
  local conman="$(select_container_manager)"
  local llm_store="--root"
  if [ "$EUID" -eq 0 ]; then
    llm_store+=" /var/lib/podman-llm/storage"
  else
    llm_store+=" $HOME/.local/share/podman-llm/storage"
  fi

  local vol="-v$HOME/.cache/huggingface/:/root/.cache/huggingface/"
  local conman_run="$conman run --rm -it --security-opt=label=disable"
  local runtime_image_name="podman-llm:latest"
  conman_run+=" -v"$HOME":"$HOME" -v/tmp:/tmp $vol"
  if [ "$1" = "run" ]; then
    local image_name="$2"
    attempt_hf_pull "$llm_store" "$image_name" "$conman_run"
    local args="llama-main -m $MODEL --log-disable --instruct"
    if [ "$image_name" == "bash" ]; then
      args="/bin/bash"
      image_name="podman-llm"
    fi

    container_id_to_copy_from="$($conman $llm_store create $image_name)"
    $conman cp $container_id_to_copy_from:$(get_model $image_name) 
    $conman_run "$runtime_image_name" $args
  elif [ "$1" = "pull" ]; then
    local image_name="$2"
    attempt_hf_pull "$llm_store" "$image_name" "$conman_run"
    $conman $llm_store pull "$image_name"
  elif [ "$1" = "serve" ]; then
    local image_name="$2"
    attempt_hf_pull "$llm_store" "$image_name" "$conman_run"
    $conman_run -p 8080:8080 "$runtime_image_name" llama-server -m $MODEL
  elif [ "$1" = "list" ] || [ "$1" = "ls" ]; then
    $conman $llm_store images
  else
    echo "Usage: podman-llm [run|pull|serve|list] image_name"
    return 1
  fi
}

main "$@"

